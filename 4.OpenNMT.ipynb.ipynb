{"cells":[{"cell_type":"markdown","metadata":{"id":"DW1_j_rLzjo1"},"source":["# OpenNMT Tutorial and Starter Code\n","(modified from the OpenNMT quickstart to work in Colab)\n","\n","While creating your own models from scratch is common for many tasks, often times it's useful to rely on a tool or framework to aid in this. In this exercise we're going to look at one popular NMT tool, OpenNMT, as a way to use beam search, which could be tricky to implement efficiently on your own.\n","\n","Finally we'll look at how to configure different models for OpenNMT including Transformer, which we'll look at in detail next week.\n","\n","OpenNMT, is similar to other ML frameworks in that it relies on a combination of editable .yaml files and command line tools to run the training procedure.  \n","### Make sure you have the *.yml config files from the lab repository.\n","\n"]},{"cell_type":"code","source":["!git clone https://github.com/OpenNMT/OpenNMT-py.git"],"metadata":{"id":"lAgZRlm7EOYK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678407552320,"user_tz":480,"elapsed":316,"user":{"displayName":"Hao Jia","userId":"07311169520047142158"}},"outputId":"2639a8ec-8f9f-4728-e0d9-ad33fa181e0c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'OpenNMT-py' already exists and is not an empty directory.\n"]}]},{"cell_type":"code","source":["!pip install --upgrade OpenNMT-py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4QnUUqGTP4jF","outputId":"204accdb-3a90-4628-ab5a-4cbd8c37f5c8","executionInfo":{"status":"ok","timestamp":1678407570369,"user_tz":480,"elapsed":4113,"user":{"displayName":"Hao Jia","userId":"07311169520047142158"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: OpenNMT-py in /usr/local/lib/python3.9/dist-packages (3.0.4)\n","Requirement already satisfied: waitress in /usr/local/lib/python3.9/dist-packages (from OpenNMT-py) (2.1.2)\n","Requirement already satisfied: tensorboard>=2.3 in /usr/local/lib/python3.9/dist-packages (from OpenNMT-py) (2.11.2)\n","Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.9/dist-packages (from OpenNMT-py) (2.13.7)\n","Requirement already satisfied: sacrebleu in /usr/local/lib/python3.9/dist-packages (from OpenNMT-py) (2.3.1)\n","Requirement already satisfied: flask in /usr/local/lib/python3.9/dist-packages (from OpenNMT-py) (2.2.3)\n","Requirement already satisfied: pyonmttok<2,>=1.35 in /usr/local/lib/python3.9/dist-packages (from OpenNMT-py) (1.37.1)\n","Requirement already satisfied: configargparse in /usr/local/lib/python3.9/dist-packages (from OpenNMT-py) (1.5.3)\n","Requirement already satisfied: ctranslate2<4,>=3.2 in /usr/local/lib/python3.9/dist-packages (from OpenNMT-py) (3.8.0)\n","Requirement already satisfied: torch>=1.12.1 in /usr/local/lib/python3.9/dist-packages (from OpenNMT-py) (1.13.1+cu116)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from OpenNMT-py) (6.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from ctranslate2<4,>=3.2->OpenNMT-py) (1.22.4)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.8.1)\n","Requirement already satisfied: protobuf<4,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.19.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.3->OpenNMT-py) (57.4.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.4.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.4.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.3->OpenNMT-py) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.3->OpenNMT-py) (0.4.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.3->OpenNMT-py) (2.16.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.3->OpenNMT-py) (2.25.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.3->OpenNMT-py) (2.2.3)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.3->OpenNMT-py) (0.38.4)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.51.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.12.1->OpenNMT-py) (4.5.0)\n","Requirement already satisfied: importlib-metadata>=3.6.0 in /usr/local/lib/python3.9/dist-packages (from flask->OpenNMT-py) (6.0.0)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.9/dist-packages (from flask->OpenNMT-py) (2.1.2)\n","Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.9/dist-packages (from flask->OpenNMT-py) (3.1.2)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.9/dist-packages (from flask->OpenNMT-py) (8.1.3)\n","Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from sacrebleu->OpenNMT-py) (2022.6.2)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.9/dist-packages (from sacrebleu->OpenNMT-py) (0.4.6)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.9/dist-packages (from sacrebleu->OpenNMT-py) (2.7.0)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from sacrebleu->OpenNMT-py) (4.9.2)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.9/dist-packages (from sacrebleu->OpenNMT-py) (0.8.10)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (4.9)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (1.15.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.2.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (5.3.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.3->OpenNMT-py) (1.3.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=3.6.0->flask->OpenNMT-py) (3.15.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from Jinja2>=3.0->flask->OpenNMT-py) (2.1.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (1.26.14)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (2.10)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.3->OpenNMT-py) (3.2.2)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R24Vt0AksrhX","outputId":"0bb58426-29a5-410a-e5cd-84f2e69e3eb4","executionInfo":{"status":"ok","timestamp":1678399188875,"user_tz":480,"elapsed":22519,"user":{"displayName":"Hao Jia","userId":"07311169520047142158"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/NVIDIA/apex.git@700d6825e205732c1d6be511306ca4e595297070 (from -r /content/OpenNMT-py/requirements.opt.txt (line 2))\n","  Cloning https://github.com/NVIDIA/apex.git (to revision 700d6825e205732c1d6be511306ca4e595297070) to /tmp/pip-req-build-nbd6rjnl\n","  Running command git clone --filter=blob:none --quiet https://github.com/NVIDIA/apex.git /tmp/pip-req-build-nbd6rjnl\n","  Running command git rev-parse -q --verify 'sha^700d6825e205732c1d6be511306ca4e595297070'\n","  Running command git fetch -q https://github.com/NVIDIA/apex.git 700d6825e205732c1d6be511306ca4e595297070\n","  Running command git checkout -q 700d6825e205732c1d6be511306ca4e595297070\n","  Resolved https://github.com/NVIDIA/apex.git to commit 700d6825e205732c1d6be511306ca4e595297070\n","  Running command git submodule update --init --recursive -q\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pyrouge\n","  Downloading pyrouge-0.1.3.tar.gz (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting sentencepiece>=0.1.94\n","  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting subword-nmt>=0.3.7\n","  Downloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n","Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.9/dist-packages (from -r /content/OpenNMT-py/requirements.opt.txt (line 5)) (2.13.7)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from subword-nmt>=0.3.7->-r /content/OpenNMT-py/requirements.opt.txt (line 4)) (4.65.0)\n","Collecting mock\n","  Downloading mock-5.0.1-py3-none-any.whl (30 kB)\n","Building wheels for collected packages: pyrouge, apex\n","  Building wheel for pyrouge (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyrouge: filename=pyrouge-0.1.3-py3-none-any.whl size=191620 sha256=dcae39f58b4bcd2f89f26273c5234b69fd94e59b05add5ce5cc262f0b24b4b4c\n","  Stored in directory: /root/.cache/pip/wheels/fc/7d/69/cdac1c301a0f9ff33c3afd94ca9ac1e809f440d7f1c4780fc4\n","  Building wheel for apex (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for apex: filename=apex-0.1-py3-none-any.whl size=192736 sha256=1a17280975b6c80587730d2348af1e8dfd01308ef0a501715ad93ed610315c88\n","  Stored in directory: /root/.cache/pip/wheels/1f/9e/bb/582fc581d041509778d9c379396a47dcdb9f4ef27b9ae36311\n","Successfully built pyrouge apex\n","Installing collected packages: sentencepiece, pyrouge, apex, mock, subword-nmt\n","Successfully installed apex-0.1 mock-5.0.1 pyrouge-0.1.3 sentencepiece-0.1.97 subword-nmt-0.3.8\n"]}],"source":["!pip install -r /content/OpenNMT-py/requirements.opt.txt"]},{"cell_type":"markdown","metadata":{"id":"LbZmSKOA4JJh"},"source":["### Next let's get OpenNMT as well as a toy English to German corpus."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f2NZIg4rnuUW","outputId":"46c3dc21-e684-426e-b639-1ae632653c80","executionInfo":{"status":"ok","timestamp":1678401705305,"user_tz":480,"elapsed":1219,"user":{"displayName":"Hao Jia","userId":"07311169520047142158"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-03-09 22:41:44--  https://s3.amazonaws.com/opennmt-trainingdata/toy-ende.tar.gz\n","Resolving s3.amazonaws.com (s3.amazonaws.com)... 54.231.224.24, 52.216.209.56, 52.216.79.30, ...\n","Connecting to s3.amazonaws.com (s3.amazonaws.com)|54.231.224.24|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1662081 (1.6M) [application/x-gzip]\n","Saving to: ‘toy-ende.tar.gz’\n","\n","toy-ende.tar.gz     100%[===================>]   1.58M  4.23MB/s    in 0.4s    \n","\n","2023-03-09 22:41:44 (4.23 MB/s) - ‘toy-ende.tar.gz’ saved [1662081/1662081]\n","\n"]}],"source":["!wget https://s3.amazonaws.com/opennmt-trainingdata/toy-ende.tar.gz\n","!tar xf toy-ende.tar.gz\n","!cd toy-ende"]},{"cell_type":"markdown","metadata":{"id":"vKXbe2KJ4Uqr"},"source":["## Processing Vocab\n","\n","Once we have the corpus and OpenNMT we can build the vocab we'll use. This relies on having a config file with this information laid out.\n","\n","Let's take a second to look at the config file we'll be using toy-ende.yml, which we will upload from the students repo into the root project directory inside our Colab environment.\n","\n","The important part of the data processing are in the top parts of the yaml file:\n","\n","```\n","# toy_en_de.yaml\n","\n","## Where the samples will be written\n","save_data: toy-ende/run/example\n","## Where the vocab(s) will be written\n","src_vocab: toy-ende/run/example.vocab.src\n","tgt_vocab: toy-ende/run/example.vocab.tgt\n","# Prevent overwriting existing files in the folder\n","overwrite: False\n","\n","# Corpus opts:\n","data:\n","    corpus_1:\n","        path_src: toy-ende/src-train.txt\n","        path_tgt: toy-ende/tgt-train.txt\n","    valid:\n","        path_src: toy-ende/src-val.txt\n","        path_tgt: toy-ende/tgt-val.txt\n","\n","```\n","In this file, we specify where the data is, where to save it, as well as the vocab files corresponding to the corpus.\n","\n","Once uploaded, we can run the cell below:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lvhOxc0XoC-Z","outputId":"4f83e487-dd27-49e1-c670-9c946b3cddaf","executionInfo":{"status":"ok","timestamp":1678401801723,"user_tz":480,"elapsed":3234,"user":{"displayName":"Hao Jia","userId":"07311169520047142158"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Corpus corpus_1's weight should be given. We default it to 1 for you.\n","[2023-03-09 22:43:20,175 INFO] Counter vocab from 10000 samples.\n","[2023-03-09 22:43:20,175 INFO] Build vocab on 10000 transformed examples/corpus.\n","[2023-03-09 22:43:20,573 INFO] Counters src:24995\n","[2023-03-09 22:43:20,573 INFO] Counters tgt:35816\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/onmt_build_vocab\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/usr/local/lib/python3.9/dist-packages/onmt/bin/build_vocab.py\", line 202, in main\n","    build_vocab_main(opts)\n","  File \"/usr/local/lib/python3.9/dist-packages/onmt/bin/build_vocab.py\", line 186, in build_vocab_main\n","    save_counter(src_counter, opts.src_vocab)\n","  File \"/usr/local/lib/python3.9/dist-packages/onmt/bin/build_vocab.py\", line 175, in save_counter\n","    check_path(save_path, exist_ok=opts.overwrite, log=logger.warning)\n","  File \"/usr/local/lib/python3.9/dist-packages/onmt/utils/misc.py\", line 47, in check_path\n","    raise IOError(f\"path {path} exists, stop.\")\n","OSError: path toy-ende/run/example.vocab.src exists, stop.\n"]}],"source":["!onmt_build_vocab -config /content/drive/MyDrive/COLX_531_lab3_jhlbxx/toy_en_de.yaml -n_sample 10000\n"]},{"cell_type":"markdown","source":["* `-n_sample` is required here -- it represents the number of lines sampled from each corpus to build the vocab.\n","* This configuration is the simplest possible, without any tokenization or other transforms. See other example configurations for more complex pipelines.\n"],"metadata":{"id":"Pfk-Y58JerRG"}},{"cell_type":"markdown","metadata":{"id":"RyDiOm9Q5Fiz"},"source":["## Training\n","\n","Next we will beging training with OpenNMT, again using the same config file, however, **adding** into it all the relevant parts we need:\n","\n","```\n","# toy_en_de.yaml\n","\n","# Train on a single GPU\n","world_size: 1\n","gpu_ranks: [0]\n","\n","# Where to save the checkpoints\n","# Note it won't actually make it to 10,000 steps because of early stopping\n","save_model: toy-ende/run/model\n","save_checkpoint_steps: 500\n","train_steps: 10000\n","valid_steps: 500\n","early_stopping: 2\n","\n","\n","# Checkpoint settings\n","keep_checkpoint: 3\n","seed: 531\n","warmup_steps: 400\n","report_every: 100\n","\n","# Model (note these are actually default values, but I've explicitely written them out to show how you can edit them)\n","decoder_type: rnn\n","encoder_type: rnn \n","enc_layers: 2\n","dec_layers: 2\n","enc_rnn_size: 500\n","dec_rnn_size: 500\n","dropout: 0.3\n","global_attention : dot\n","\n","\n","# Optimizer settings\n","optim: sgd\n","learning_rate: 1\n","\n","```\n","\n","Here the config file covers two major things: Model checkpointing and Model Hyperparameters.\n","\n","Certain settings are available only for certain models, for instance you wouldn't (want to) use positional encoding for an RNN-based model, however, it is necessary for proper training of Transformers and we could include it if we added a line ```positional_encoding: 'true'```.\n","\n","If we wanted to know more about any of these settings, we could take a peek at the OpenNMT [train documentation](https://opennmt.net/OpenNMT-py/options/train.html)\n","\n","For instance for the encoder options, it shows what available models can be used:\n","```\n","--encoder_type, -encoder_type\n","Possible choices: rnn, brnn, ggnn, mean, transformer, cnn, transformer_lm\n","\n","Type of encoder layer to use. Non-RNN layers are experimental. Options are [rnn|brnn|ggnn|mean|transformer|cnn|transformer_lm].\n","\n","```\n","\n","\n","Finally we will train our model with this configuration. (It took about 10 minutes for the small RNN model to train). "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GJmdN6G_qnjo","outputId":"7b199610-55d6-4f63-b60a-4466cc44357d","executionInfo":{"status":"ok","timestamp":1678400392798,"user_tz":480,"elapsed":364853,"user":{"displayName":"Hao Jia","userId":"07311169520047142158"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[2023-03-09 22:13:49,714 INFO] Missing transforms field for corpus_1 data, set to default: [].\n","[2023-03-09 22:13:49,715 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n","[2023-03-09 22:13:49,715 INFO] Missing transforms field for valid data, set to default: [].\n","[2023-03-09 22:13:49,715 INFO] Parsed 2 corpora from -data.\n","[2023-03-09 22:13:49,715 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n","[2023-03-09 22:13:49,872 INFO] Building model...\n","[2023-03-09 22:13:58,941 INFO] NMTModel(\n","  (encoder): RNNEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(25000, 500, padding_idx=1)\n","        )\n","      )\n","      (dropout): Dropout(p=0.3, inplace=False)\n","    )\n","    (rnn): LSTM(500, 500, num_layers=2, batch_first=True, dropout=0.3)\n","  )\n","  (decoder): InputFeedRNNDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(32768, 500, padding_idx=1)\n","        )\n","      )\n","      (dropout): Dropout(p=0.3, inplace=False)\n","    )\n","    (dropout): Dropout(p=0.3, inplace=False)\n","    (rnn): StackedLSTM(\n","      (dropout): Dropout(p=0.3, inplace=False)\n","      (layers): ModuleList(\n","        (0): LSTMCell(1000, 500)\n","        (1): LSTMCell(500, 500)\n","      )\n","    )\n","    (attn): GlobalAttention(\n","      (linear_out): Linear(in_features=1000, out_features=500, bias=False)\n","    )\n","  )\n","  (generator): Linear(in_features=500, out_features=32768, bias=True)\n",")\n","[2023-03-09 22:13:58,941 INFO] encoder: 16508000\n","[2023-03-09 22:13:58,941 INFO] decoder: 38308768\n","[2023-03-09 22:13:58,941 INFO] * number of parameters: 54816768\n","[2023-03-09 22:13:58,942 INFO]  * src vocab size = 25000\n","[2023-03-09 22:13:58,942 INFO]  * tgt vocab size = 32768\n","[2023-03-09 22:13:58,943 INFO] Starting training on GPU: [0]\n","[2023-03-09 22:13:58,943 INFO] Start training loop and validate every 500 steps...\n","[2023-03-09 22:13:58,943 INFO] Scoring with: TransformPipe()\n","[2023-03-09 22:14:00,219 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 1\n","[2023-03-09 22:14:01,379 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 1\n","[2023-03-09 22:14:01,483 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 2\n","[2023-03-09 22:14:01,524 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 2\n","[2023-03-09 22:14:01,585 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 3\n","[2023-03-09 22:14:01,624 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 3\n","[2023-03-09 22:14:01,818 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 4\n","[2023-03-09 22:14:01,863 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 4\n","[2023-03-09 22:14:01,923 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 5\n","[2023-03-09 22:14:01,967 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 5\n","[2023-03-09 22:14:02,030 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 6\n","[2023-03-09 22:14:02,095 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 6\n","[2023-03-09 22:14:02,141 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 7\n","[2023-03-09 22:14:02,200 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 7\n","[2023-03-09 22:14:02,463 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 8\n","[2023-03-09 22:14:02,514 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 8\n","[2023-03-09 22:14:02,579 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 9\n","[2023-03-09 22:14:02,622 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 9\n","[2023-03-09 22:14:02,683 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 10\n","[2023-03-09 22:14:02,728 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 10\n","[2023-03-09 22:14:03,117 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 11\n","[2023-03-09 22:14:03,121 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 11\n","[2023-03-09 22:14:03,221 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 12\n","[2023-03-09 22:14:03,229 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 12\n","[2023-03-09 22:14:03,328 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 13\n","[2023-03-09 22:14:03,335 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 13\n","[2023-03-09 22:14:03,807 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 14\n","[2023-03-09 22:14:03,819 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 14\n","[2023-03-09 22:14:03,913 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 15\n","[2023-03-09 22:14:03,923 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 15\n","[2023-03-09 22:14:04,017 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 16\n","[2023-03-09 22:14:04,025 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 16\n","[2023-03-09 22:14:04,144 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 17\n","[2023-03-09 22:14:04,151 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 17\n","[2023-03-09 22:14:04,747 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 18\n","[2023-03-09 22:14:04,758 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 18\n","[2023-03-09 22:14:04,855 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 19\n","[2023-03-09 22:14:04,867 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 19\n","[2023-03-09 22:14:04,964 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 20\n","[2023-03-09 22:14:04,972 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 20\n","[2023-03-09 22:14:05,069 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 21\n","[2023-03-09 22:14:05,077 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 21\n","[2023-03-09 22:14:05,184 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 22\n","[2023-03-09 22:14:05,194 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 22\n","[2023-03-09 22:14:05,297 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 23\n","[2023-03-09 22:14:05,297 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 23\n","[2023-03-09 22:14:06,021 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 24\n","[2023-03-09 22:14:06,043 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 24\n","[2023-03-09 22:14:06,154 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 25\n","[2023-03-09 22:14:06,213 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 25\n","[2023-03-09 22:14:06,285 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 26\n","[2023-03-09 22:14:06,411 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 27\n","[2023-03-09 22:14:06,424 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 26\n","[2023-03-09 22:14:06,574 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 28\n","[2023-03-09 22:14:06,609 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 27\n","[2023-03-09 22:14:06,796 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 29\n","[2023-03-09 22:14:06,820 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 28\n","[2023-03-09 22:14:07,035 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 29\n","[2023-03-09 22:14:08,503 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 30\n","[2023-03-09 22:14:08,713 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 31\n","[2023-03-09 22:14:08,748 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 30\n","[2023-03-09 22:14:08,907 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 32\n","[2023-03-09 22:14:08,958 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 31\n","[2023-03-09 22:14:09,135 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 33\n","[2023-03-09 22:14:09,174 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 32\n","[2023-03-09 22:14:09,345 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 34\n","[2023-03-09 22:14:09,393 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 33\n","[2023-03-09 22:14:09,563 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 35\n","[2023-03-09 22:14:09,610 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 34\n","[2023-03-09 22:14:09,783 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 36\n","[2023-03-09 22:14:09,840 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 35\n","[2023-03-09 22:14:09,995 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 37\n","[2023-03-09 22:14:10,049 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 36\n","[2023-03-09 22:14:10,223 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 38\n","[2023-03-09 22:14:10,272 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 37\n","[2023-03-09 22:14:10,439 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 38\n","[2023-03-09 22:14:11,456 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 39\n","[2023-03-09 22:14:11,565 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 40\n","[2023-03-09 22:14:11,573 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 39\n","[2023-03-09 22:14:11,669 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 41\n","[2023-03-09 22:14:11,680 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 40\n","[2023-03-09 22:14:11,799 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 42\n","[2023-03-09 22:14:11,817 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 41\n","[2023-03-09 22:14:11,901 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 43\n","[2023-03-09 22:14:11,924 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 42\n","[2023-03-09 22:14:12,012 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 44\n","[2023-03-09 22:14:12,029 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 43\n","[2023-03-09 22:14:12,118 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 45\n","[2023-03-09 22:14:12,136 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 44\n","[2023-03-09 22:14:12,222 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 46\n","[2023-03-09 22:14:12,251 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 45\n","[2023-03-09 22:14:12,335 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 47\n","[2023-03-09 22:14:12,355 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 46\n","[2023-03-09 22:14:12,450 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 48\n","[2023-03-09 22:14:12,491 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 47\n","[2023-03-09 22:14:12,601 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 48\n","[2023-03-09 22:14:13,876 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 49\n","[2023-03-09 22:14:13,980 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 50\n","[2023-03-09 22:14:14,025 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 49\n","[2023-03-09 22:14:14,088 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 51\n","[2023-03-09 22:14:14,133 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 50\n","[2023-03-09 22:14:14,198 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 52\n","[2023-03-09 22:14:14,240 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 51\n","[2023-03-09 22:14:14,307 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 53\n","[2023-03-09 22:14:14,350 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 52\n","[2023-03-09 22:14:14,455 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 53\n","[2023-03-09 22:14:42,077 INFO] Step 100/10000; acc: 4.1; ppl: 49263.0; xent: 10.8; lr: 1.00000; sents:    6400; bsz: 1304/1297/64; 3023/3006 tok/s;     43 sec;\n","[2023-03-09 22:14:52,577 INFO] Step 200/10000; acc: 6.4; ppl: 5055.1; xent: 8.5; lr: 1.00000; sents:    6400; bsz: 1379/1368/64; 13131/13026 tok/s;     54 sec;\n","[2023-03-09 22:15:03,341 INFO] Step 300/10000; acc: 9.1; ppl: 1760.4; xent: 7.5; lr: 1.00000; sents:    6400; bsz: 1427/1415/64; 13261/13143 tok/s;     64 sec;\n","[2023-03-09 22:15:14,084 INFO] Step 400/10000; acc: 10.1; ppl: 1264.1; xent: 7.1; lr: 1.00000; sents:    6400; bsz: 1387/1380/64; 12914/12844 tok/s;     75 sec;\n","[2023-03-09 22:15:24,071 INFO] Step 500/10000; acc: 11.7; ppl: 972.6; xent: 6.9; lr: 1.00000; sents:    6400; bsz: 1259/1261/64; 12606/12629 tok/s;     85 sec;\n","[2023-03-09 22:15:32,600 INFO] valid stats calculation and sentences rebuilding\n","                           took: 8.527912616729736 s.\n","[2023-03-09 22:15:32,601 INFO] Train perplexity: 3468.35\n","[2023-03-09 22:15:32,601 INFO] Train accuracy: 8.29374\n","[2023-03-09 22:15:32,601 INFO] Sentences processed: 32000\n","[2023-03-09 22:15:32,601 INFO] Average bsz: 1351/1344/64\n","[2023-03-09 22:15:32,601 INFO] Validation perplexity: 651.946\n","[2023-03-09 22:15:32,601 INFO] Validation accuracy: 10.7639\n","[2023-03-09 22:15:32,601 INFO] Model is improving ppl: inf --> 651.946.\n","[2023-03-09 22:15:32,601 INFO] Model is improving acc: -inf --> 10.7639.\n","[2023-03-09 22:15:32,621 INFO] Saving checkpoint toy-ende/run/model_step_500.pt\n","[2023-03-09 22:15:43,867 INFO] Step 600/10000; acc: 12.3; ppl: 816.2; xent: 6.7; lr: 1.00000; sents:    6400; bsz: 1342/1331/64; 6778/6726 tok/s;    105 sec;\n","[2023-03-09 22:15:54,537 INFO] Step 700/10000; acc: 13.2; ppl: 697.5; xent: 6.5; lr: 1.00000; sents:    6400; bsz: 1347/1338/64; 12626/12539 tok/s;    116 sec;\n","[2023-03-09 22:16:05,207 INFO] Step 800/10000; acc: 14.4; ppl: 577.0; xent: 6.4; lr: 1.00000; sents:    6400; bsz: 1350/1341/64; 12649/12563 tok/s;    126 sec;\n","[2023-03-09 22:16:15,592 INFO] Step 900/10000; acc: 15.0; ppl: 530.3; xent: 6.3; lr: 1.00000; sents:    6400; bsz: 1341/1333/64; 12918/12837 tok/s;    137 sec;\n","[2023-03-09 22:16:26,044 INFO] Step 1000/10000; acc: 16.4; ppl: 433.4; xent: 6.1; lr: 1.00000; sents:    6400; bsz: 1238/1230/64; 11848/11767 tok/s;    147 sec;\n","[2023-03-09 22:16:35,238 INFO] valid stats calculation and sentences rebuilding\n","                           took: 9.193364381790161 s.\n","[2023-03-09 22:16:35,240 INFO] Train perplexity: 1456.04\n","[2023-03-09 22:16:35,242 INFO] Train accuracy: 11.2114\n","[2023-03-09 22:16:35,242 INFO] Sentences processed: 64000\n","[2023-03-09 22:16:35,242 INFO] Average bsz: 1337/1329/64\n","[2023-03-09 22:16:35,242 INFO] Validation perplexity: 333.865\n","[2023-03-09 22:16:35,242 INFO] Validation accuracy: 15.2345\n","[2023-03-09 22:16:35,242 INFO] Model is improving ppl: 651.946 --> 333.865.\n","[2023-03-09 22:16:35,242 INFO] Model is improving acc: 10.7639 --> 15.2345.\n","[2023-03-09 22:16:35,272 INFO] Saving checkpoint toy-ende/run/model_step_1000.pt\n","[2023-03-09 22:16:46,608 INFO] Step 1100/10000; acc: 16.3; ppl: 403.0; xent: 6.0; lr: 1.00000; sents:    6400; bsz: 1379/1373/64; 6705/6676 tok/s;    168 sec;\n","[2023-03-09 22:16:57,546 INFO] Step 1200/10000; acc: 17.3; ppl: 346.3; xent: 5.8; lr: 1.00000; sents:    6400; bsz: 1400/1392/64; 12803/12731 tok/s;    179 sec;\n","[2023-03-09 22:17:08,700 INFO] Step 1300/10000; acc: 17.6; ppl: 310.5; xent: 5.7; lr: 1.00000; sents:    6400; bsz: 1410/1409/64; 12642/12632 tok/s;    190 sec;\n","[2023-03-09 22:17:19,407 INFO] Step 1400/10000; acc: 18.8; ppl: 260.8; xent: 5.6; lr: 1.00000; sents:    6400; bsz: 1354/1352/64; 12644/12628 tok/s;    200 sec;\n","[2023-03-09 22:17:30,241 INFO] Step 1500/10000; acc: 18.8; ppl: 244.2; xent: 5.5; lr: 1.00000; sents:    6400; bsz: 1399/1397/64; 12912/12891 tok/s;    211 sec;\n","[2023-03-09 22:17:39,671 INFO] valid stats calculation and sentences rebuilding\n","                           took: 9.42957329750061 s.\n","[2023-03-09 22:17:39,672 INFO] Train perplexity: 855.111\n","[2023-03-09 22:17:39,672 INFO] Train accuracy: 13.45\n","[2023-03-09 22:17:39,672 INFO] Sentences processed: 96000\n","[2023-03-09 22:17:39,672 INFO] Average bsz: 1354/1348/64\n","[2023-03-09 22:17:39,672 INFO] Validation perplexity: 264.078\n","[2023-03-09 22:17:39,672 INFO] Validation accuracy: 20.0171\n","[2023-03-09 22:17:39,672 INFO] Model is improving ppl: 333.865 --> 264.078.\n","[2023-03-09 22:17:39,672 INFO] Model is improving acc: 15.2345 --> 20.0171.\n","[2023-03-09 22:17:39,687 INFO] Saving checkpoint toy-ende/run/model_step_1500.pt\n","[2023-03-09 22:17:51,165 INFO] Step 1600/10000; acc: 19.8; ppl: 215.1; xent: 5.4; lr: 1.00000; sents:    6400; bsz: 1381/1375/64; 6599/6570 tok/s;    232 sec;\n","[2023-03-09 22:18:02,436 INFO] Step 1700/10000; acc: 20.1; ppl: 188.1; xent: 5.2; lr: 1.00000; sents:    6400; bsz: 1426/1419/64; 12653/12593 tok/s;    243 sec;\n","[2023-03-09 22:18:13,547 INFO] Step 1800/10000; acc: 20.8; ppl: 170.5; xent: 5.1; lr: 1.00000; sents:    6400; bsz: 1427/1414/64; 12839/12727 tok/s;    255 sec;\n","[2023-03-09 22:18:24,577 INFO] Step 1900/10000; acc: 21.8; ppl: 143.9; xent: 5.0; lr: 1.00000; sents:    6400; bsz: 1403/1399/64; 12722/12685 tok/s;    266 sec;\n","[2023-03-09 22:18:35,375 INFO] Step 2000/10000; acc: 22.3; ppl: 129.9; xent: 4.9; lr: 1.00000; sents:    6400; bsz: 1367/1357/64; 12661/12565 tok/s;    276 sec;\n","[2023-03-09 22:18:44,789 INFO] valid stats calculation and sentences rebuilding\n","                           took: 9.412956476211548 s.\n","[2023-03-09 22:18:44,790 INFO] Train perplexity: 562.646\n","[2023-03-09 22:18:44,790 INFO] Train accuracy: 15.3707\n","[2023-03-09 22:18:44,790 INFO] Sentences processed: 128000\n","[2023-03-09 22:18:44,790 INFO] Average bsz: 1366/1359/64\n","[2023-03-09 22:18:44,790 INFO] Validation perplexity: 255.978\n","[2023-03-09 22:18:44,790 INFO] Validation accuracy: 18.6537\n","[2023-03-09 22:18:44,790 INFO] Stalled patience: 1/2\n","[2023-03-09 22:18:44,812 INFO] Saving checkpoint toy-ende/run/model_step_2000.pt\n","[2023-03-09 22:18:55,559 INFO] Step 2100/10000; acc: 23.1; ppl: 120.8; xent: 4.8; lr: 1.00000; sents:    6400; bsz: 1294/1279/64; 6410/6337 tok/s;    297 sec;\n","[2023-03-09 22:19:06,191 INFO] Step 2200/10000; acc: 23.6; ppl: 102.6; xent: 4.6; lr: 1.00000; sents:    6400; bsz: 1352/1343/64; 12713/12632 tok/s;    307 sec;\n","[2023-03-09 22:19:17,873 INFO] Step 2300/10000; acc: 23.6; ppl: 105.5; xent: 4.7; lr: 1.00000; sents:    6400; bsz: 1452/1444/64; 12430/12365 tok/s;    319 sec;\n","[2023-03-09 22:19:29,412 INFO] Step 2400/10000; acc: 24.9; ppl:  88.0; xent: 4.5; lr: 1.00000; sents:    6400; bsz: 1386/1380/64; 12009/11963 tok/s;    330 sec;\n","[2023-03-09 22:19:39,437 INFO] Step 2500/10000; acc: 26.0; ppl:  77.3; xent: 4.3; lr: 1.00000; sents:    6400; bsz: 1278/1271/64; 12747/12676 tok/s;    340 sec;\n","[2023-03-09 22:19:49,016 INFO] valid stats calculation and sentences rebuilding\n","                           took: 9.577903270721436 s.\n","[2023-03-09 22:19:49,016 INFO] Train perplexity: 397.798\n","[2023-03-09 22:19:49,016 INFO] Train accuracy: 17.1296\n","[2023-03-09 22:19:49,016 INFO] Sentences processed: 160000\n","[2023-03-09 22:19:49,016 INFO] Average bsz: 1363/1356/64\n","[2023-03-09 22:19:49,016 INFO] Validation perplexity: 268.679\n","[2023-03-09 22:19:49,016 INFO] Validation accuracy: 20.6319\n","[2023-03-09 22:19:49,016 INFO] Stalled patience: 0/2\n","[2023-03-09 22:19:49,016 INFO] Training finished after stalled validations. Early Stop!\n","[2023-03-09 22:19:49,017 INFO] Best model found at step 1500\n","[2023-03-09 22:19:49,017 INFO] earlystopper has_stopped!\n","[2023-03-09 22:19:50,926 INFO] Saving checkpoint toy-ende/run/model_step_2500.pt\n"]}],"source":["!onmt_train -config /content/drive/MyDrive/COLX_531_lab3_jhlbxx/toy_en_de.yaml"]},{"cell_type":"markdown","metadata":{"id":"IYpT9fpCziZJ"},"source":["Once our model is saved. We can use it to actually generate predictions on our output files. Our models will be saved under the ```save_model``` setting of our config file, in this case: ```toy-ende/run/model_```  Since we are only saving every 500 training steps, and keeping the past three checkpoints, we can choose from the available models. ```model_step_2500.pt``` and ```model_step_3000.pt``` and ```model_step_3500.pt```. Our early stopping indicates the best model (lowest perplexity/highest acc) of the three is 2500, but let's look at how to pick between these three using BLEU:\n","\n","## Translating\n","\n","To do so we will need to translate the source sentences, decoding with Beam search, in this case we've chosen a ```-beam_size``` of 10, however you will be asked in the question to adjust it to different sizes.\n","\n","Let's first create predictions for our ```_step_2500.pt```, ```_step_3000.pt``` , ```_step_3500.pt``` models (NOTE YOUR MODEL MAY HAVE STOPPED AT A DIFFERENT POINT, IN WHICH CASE USE THE APPROPRIATE 3 LAST CHECKPOINTS):"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"myhsvgu34DAj","outputId":"69f3764c-a11a-4b22-9b8c-f859578d15ab","executionInfo":{"status":"ok","timestamp":1678402958723,"user_tz":480,"elapsed":608945,"user":{"displayName":"Hao Jia","userId":"07311169520047142158"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[2023-03-09 22:55:53,705 INFO] PRED SCORE: -1.6577, PRED PPL: 5.25 NB SENTENCES: 3000\n","[2023-03-09 22:59:22,300 INFO] PRED SCORE: -1.5070, PRED PPL: 4.51 NB SENTENCES: 3000\n","[2023-03-09 23:02:37,808 INFO] PRED SCORE: -1.4296, PRED PPL: 4.18 NB SENTENCES: 3000\n"]}],"source":["!onmt_translate -model toy-ende/run/model_step_1500.pt -src toy-ende/src-val.txt -output toy-ende/val_2500.txt -gpu 0 -beam_size 10 -seed 531 -block_ngram 2\n","!onmt_translate -model toy-ende/run/model_step_2000.pt -src toy-ende/src-val.txt -output toy-ende/val_3000.txt -gpu 0 -beam_size 10 -seed 531 -block_ngram 2\n","!onmt_translate -model toy-ende/run/model_step_2500.pt -src toy-ende/src-val.txt -output toy-ende/val_3500.txt -gpu 0 -beam_size 10 -seed 531 -block_ngram 2\n"]},{"cell_type":"markdown","metadata":{"id":"bt-Z2qmTAzQa"},"source":["[Note we can now manually inspect the results under val_*.txt]\n","\n","Finally let's calculate the BLEU scores of the outputs! We would eventually want to select the model with Highest BLEU (in our case 37 with our 2500 step model) and use this on our test set.\n","\n","We will upload the file `multi-bleu.perl` from the students repo into the root project directory and run it as follows:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j7NMugxgA34T","outputId":"37985d63-6ca5-416a-c414-15a6a0b46514","executionInfo":{"status":"ok","timestamp":1678403063980,"user_tz":480,"elapsed":2800,"user":{"displayName":"Hao Jia","userId":"07311169520047142158"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Use of uninitialized value in division (/) at OpenNMT-py/tools/multi-bleu-detok.perl line 149, <STDIN> line 3000.\n","BLEU = 0.00, 17.7/1.3/0.2/0.0 (BP=0.794, ratio=0.812, hyp_len=59251, ref_len=72954)\n","Use of uninitialized value in division (/) at OpenNMT-py/tools/multi-bleu-detok.perl line 149, <STDIN> line 3000.\n","BLEU = 0.00, 19.2/1.1/0.1/0.0 (BP=0.649, ratio=0.698, hyp_len=50937, ref_len=72954)\n","BLEU = 0.13, 14.6/0.6/0.0/0.0 (BP=0.924, ratio=0.927, hyp_len=67614, ref_len=72954)\n"]}],"source":["!perl  OpenNMT-py/tools/multi-bleu-detok.perl toy-ende/tgt-val.txt < toy-ende/val_2500.txt\n","!perl  OpenNMT-py/tools/multi-bleu-detok.perl toy-ende/tgt-val.txt < toy-ende/val_3000.txt\n","!perl  OpenNMT-py/tools/multi-bleu-detok.perl toy-ende/tgt-val.txt < toy-ende/val_3500.txt"]},{"cell_type":"markdown","metadata":{"id":"UylIL0MBg-NO"},"source":["# Lab 3 - Exercise 1\n","\n","We have seen how OpenNMT can be used, now let's apply it to our Multi30k dataset.\n","\n","You can run your code in here and then download the results to submit on github.\n","\n","*You are provided with a `Multi30k.yaml` to fill in, be sure to submit this alongside your colab notebook and other files in the repository.*\n","\n","## 1.1\n","\n","### Build the vocab for the Multi30k En-Fr dataset\n","\n","While just having a vocabulary is fine for some cases, using a sub-word tokenization might help capture morphological information better.\n","\n","To do this, in your config file add ```transforms: [filtertoolong]``` to the training corpora.\n","\n","Please provide the code you ran to build the vocab as well as the \"data\" section of your multi30k config file.\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"j0DCbV3TDEW4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678399034071,"user_tz":480,"elapsed":15498,"user":{"displayName":"Hao Jia","userId":"07311169520047142158"}},"outputId":"7e927938-abf8-4408-f63a-0fa43c292e25"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"93KD6CBVjcQu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678411499547,"user_tz":480,"elapsed":26337,"user":{"displayName":"Hao Jia","userId":"07311169520047142158"}},"outputId":"9ebd4bd9-7432-47ae-c408-595331e83721"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('fr_core_news_sm')\n"]}],"source":["import spacy.cli\n","\n","spacy.cli.download(\"en_core_web_sm\")\n","spacy.cli.download(\"fr_core_news_sm\")"]},{"cell_type":"code","source":["import fr_core_news_sm\n","import en_core_web_sm\n","import pandas as pd\n","\n","spacy_fr = fr_core_news_sm.load()\n","spacy_en = en_core_web_sm.load()"],"metadata":{"id":"pGHZTEB_Camv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Before using `OpenMT` to load our vocabs, we need to decouple the French and English sentences from the original Multi30k dataset and save them in a separate file. You can use the below code to do this:"],"metadata":{"id":"lwIYS2-kLTtl"}},{"cell_type":"code","source":["# THIS CODE GENERATES THE TOKENIZED FILES FOR EACH LANGUAGE\n","\n","import csv\n","from tqdm import tqdm\n","\n","FILE_LIST = [\"train_eng_fre.tsv\", \"val_eng_fre.tsv\", \"test_eng_fre.tsv\"]\n","\n","# NOTE: update with your desired path\n","path = \"/content/drive/MyDrive/COLX_531_lab3_jhlbxx/data/\"\n","\n","for file in FILE_LIST:\n","  with open(path + file, \"r\", encoding=\"utf-8\") as tsv:\n","    tsv_reader = csv.reader(tsv, delimiter=\"\\t\")\n","    next(tsv_reader, None)\n","    outfile_fr = file.split(\"_\")[0] + \"_fr.tokd\"\n","    outfile_en = file.split(\"_\")[0] + \"_en.tokd\"\n","    with open(path + outfile_fr, \"w\", encoding=\"utf-8\") as out_fr:\n","      with open(path + outfile_en, \"w\", encoding=\"utf-8\") as out_en:\n","        for row in tqdm(tsv_reader):\n","          tokenized_en = [tok.text for tok in spacy_en(row[0])]\n","          tokenized_fr = [tok.text for tok in spacy_fr(row[1])]\n","          out_fr.write(\" \".join(tokenized_fr) + \"\\n\")\n","          out_en.write(\" \".join(tokenized_en) + \"\\n\")"],"metadata":{"id":"gzGm_prfLjVl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678411956276,"user_tz":480,"elapsed":439911,"user":{"displayName":"Hao Jia","userId":"07311169520047142158"}},"outputId":"af3ab889-40a7-40d3-bbc6-5f4a10e2daae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["29000it [06:51, 70.47it/s]\n","1014it [00:14, 71.19it/s]\n","1000it [00:13, 71.60it/s]\n"]}]},{"cell_type":"code","source":["!onmt_build_vocab -config /content/drive/MyDrive/COLX_531_lab3_jhlbxx/multi30k.yml -n_sample 10000"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iEJjlcGx1jlc","executionInfo":{"status":"ok","timestamp":1678412061030,"user_tz":480,"elapsed":1772,"user":{"displayName":"Hao Jia","userId":"07311169520047142158"}},"outputId":"4d9478d5-4e5f-4b41-a856-e159fda26164"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Corpus corpus_1's weight should be given. We default it to 1 for you.\n","[2023-03-10 01:34:20,451 INFO] Counter vocab from 10000 samples.\n","[2023-03-10 01:34:20,451 INFO] Build vocab on 10000 transformed examples/corpus.\n","[2023-03-10 01:34:20,636 INFO] Counters src:6886\n","[2023-03-10 01:34:20,636 INFO] Counters tgt:6411\n"]}]},{"cell_type":"markdown","metadata":{"id":"OsVLrM0Pjfn8"},"source":["```\n","Changes made to Data saving, Corpus, and Vocab section in the config file go HERE\n","````"]},{"cell_type":"code","source":["# TODO Train Model\n","# multi30k.yaml\n","\n","## TO DO COMPLETE DATA SAVING\n","## Where the samples will be written\n","save_data: /content/drive/MyDrive/lab3_results/multi30k/run/example\n","## Where the vocab(s) will be written\n","src_vocab: /content/drive/MyDrive/lab3_results/multi30k/run/example.vocab.src\n","tgt_vocab: /content/drive/MyDrive/lab3_results/multi30k/run/example.vocab.tgt\n","# Prevent overwriting existing files in the folder\n","overwrite: False\n","\n","\n","# Corpus opts:\n","data:\n","## TODO COMPLETE CORPUS OPTIONS\n","    corpus_1:\n","        path_src: /content/drive/MyDrive/COLX_531_lab3_jhlbxx/data/train_fr.tokd\n","        path_tgt: /content/drive/MyDrive/COLX_531_lab3_jhlbxx/data/train_en.tokd\n","        transforms: [filtertoolong]\n","    valid:\n","        path_src: /content/drive/MyDrive/COLX_531_lab3_jhlbxx/data/val_fr.tokd\n","        path_tgt: /content/drive/MyDrive/COLX_531_lab3_jhlbxx/data/val_en.tokd\n","## Add sentencepiece and filter long segments\n","    \n","\n","\n","#TODO Fill in vocab you create\n","src_vocab: /content/drive/MyDrive/lab3_results/multi30k/run/example.vocab.src\n","tgt_vocab: /content/drive/MyDrive/lab3_results/multi30k/run/example.vocab.tgt"],"metadata":{"id":"9o_QKUH4ssfH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B05G-PaWl0L-"},"source":["## 1.2\n","Train Model\n","\n","Fill in the `multi30k.yaml` config to setup a seq2seq model that has a 3 layer RNN encoder 2 layer RNN decoder, MLP attention, with 20% dropout, using Adam as your optimizer.\n","\n","Copy and paste the changed parts of the *.yml file below along with the training command you used."]},{"cell_type":"markdown","metadata":{"id":"xBlHa2Wlm4Q9"},"source":["```\n","Changes to model, and optimizer here.\n","\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MWcx3Uuamdil"},"outputs":[],"source":["# Train on a single GPU\n","world_size: 1\n","gpu_ranks: [0]\n","\n","# Where to save the checkpoints\n","# Note it won't actually make it to 10,000 steps because of early stopping\n","save_model: /content/drive/MyDrive/lab3_results/multi30k/run/model\n","save_checkpoint_steps: 500\n","train_steps: 10000\n","valid_steps: 500\n","early_stopping: 2\n","\n","\n","# Checkpoint settings\n","keep_checkpoint: 5\n","seed: 531\n","warmup_steps: 400\n","report_every: 100\n","\n","# Model \n","## TODO Create RNN enc/dec with MLP attention\n","## Should have 3 layers in encoder and 2 layers in decoder\n","## 20% dropout and 500 hidden units\n","decoder_type: rnn\n","encoder_type: rnn \n","enc_layers: 3\n","dec_layers: 2\n","enc_rnn_size: 500\n","dec_rnn_size: 500\n","dropout: 0.2\n","global_attention : mlp\n","\n","\n","# Optimizer settings\n","## TODO Set Adam as Optimizer\n","optim: adam\n","learning_rate: 0.001"]},{"cell_type":"markdown","metadata":{"id":"H6WGJkJym-y9"},"source":["## 1.3\n","\n","Decoding\n","\n","Create predictions for the validation set using your saved models and select the one that has the highest BLEU. You should set beam size to 5 for each of these models.\n","\n","Report the BLEU on this model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M3n0ezhfm9q9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678412643629,"user_tz":480,"elapsed":377437,"user":{"displayName":"Hao Jia","userId":"07311169520047142158"}},"outputId":"86e69d5b-9bbb-42c2-f04c-74a1f977ac67"},"outputs":[{"output_type":"stream","name":"stdout","text":["[2023-03-10 01:37:48,578 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n","[2023-03-10 01:37:48,578 INFO] Missing transforms field for valid data, set to default: [].\n","[2023-03-10 01:37:48,578 INFO] Parsed 2 corpora from -data.\n","[2023-03-10 01:37:48,579 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n","[2023-03-10 01:37:48,640 INFO] Building model...\n","[2023-03-10 01:37:51,588 INFO] NMTModel(\n","  (encoder): RNNEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(6896, 500, padding_idx=1)\n","        )\n","      )\n","      (dropout): Dropout(p=0.2, inplace=False)\n","    )\n","    (rnn): LSTM(500, 500, num_layers=3, batch_first=True, dropout=0.2)\n","  )\n","  (decoder): InputFeedRNNDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(6416, 500, padding_idx=1)\n","        )\n","      )\n","      (dropout): Dropout(p=0.2, inplace=False)\n","    )\n","    (dropout): Dropout(p=0.2, inplace=False)\n","    (rnn): StackedLSTM(\n","      (dropout): Dropout(p=0.2, inplace=False)\n","      (layers): ModuleList(\n","        (0): LSTMCell(1000, 500)\n","        (1): LSTMCell(500, 500)\n","      )\n","    )\n","    (attn): GlobalAttention(\n","      (linear_context): Linear(in_features=500, out_features=500, bias=False)\n","      (linear_query): Linear(in_features=500, out_features=500, bias=True)\n","      (v): Linear(in_features=500, out_features=1, bias=False)\n","      (linear_out): Linear(in_features=1000, out_features=500, bias=True)\n","    )\n","  )\n","  (generator): Linear(in_features=500, out_features=6416, bias=True)\n",")\n","[2023-03-10 01:37:51,589 INFO] encoder: 9460000\n","[2023-03-10 01:37:51,589 INFO] decoder: 12431916\n","[2023-03-10 01:37:51,589 INFO] * number of parameters: 21891916\n","[2023-03-10 01:37:51,589 INFO]  * src vocab size = 6896\n","[2023-03-10 01:37:51,589 INFO]  * tgt vocab size = 6416\n","[2023-03-10 01:37:51,591 INFO] Starting training on GPU: [0]\n","[2023-03-10 01:37:51,591 INFO] Start training loop and validate every 500 steps...\n","[2023-03-10 01:37:51,591 INFO] Scoring with: TransformPipe()\n","[2023-03-10 01:37:52,825 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 1\n","[2023-03-10 01:37:53,998 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 1\n","[2023-03-10 01:37:54,183 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 2\n","[2023-03-10 01:37:54,247 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 2\n","[2023-03-10 01:37:54,459 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 3\n","[2023-03-10 01:37:54,595 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 3\n","[2023-03-10 01:37:54,827 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 4\n","[2023-03-10 01:37:54,989 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 4\n","[2023-03-10 01:37:55,233 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 5\n","[2023-03-10 01:37:55,448 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 5\n","[2023-03-10 01:37:55,714 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 6\n","[2023-03-10 01:37:56,004 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 6\n","[2023-03-10 01:37:56,279 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 7\n","[2023-03-10 01:37:56,443 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 8\n","[2023-03-10 01:37:56,669 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 7\n","[2023-03-10 01:37:56,883 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 8\n","[2023-03-10 01:37:57,145 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 9\n","[2023-03-10 01:37:57,309 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 10\n","[2023-03-10 01:37:57,646 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 9\n","[2023-03-10 01:37:57,848 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 10\n","[2023-03-10 01:37:58,121 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 11\n","[2023-03-10 01:37:58,293 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 12\n","[2023-03-10 01:37:58,461 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 13\n","[2023-03-10 01:37:58,790 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 11\n","[2023-03-10 01:37:58,993 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 12\n","[2023-03-10 01:37:59,237 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 13\n","[2023-03-10 01:37:59,620 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 14\n","[2023-03-10 01:37:59,901 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 15\n","[2023-03-10 01:38:00,271 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 16\n","[2023-03-10 01:38:00,646 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 17\n","[2023-03-10 01:38:01,095 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 14\n","[2023-03-10 01:38:01,529 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 15\n","[2023-03-10 01:38:01,986 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 16\n","[2023-03-10 01:38:02,431 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 17\n","[2023-03-10 01:38:02,677 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 18\n","[2023-03-10 01:38:02,989 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 19\n","[2023-03-10 01:38:04,485 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 18\n","[2023-03-10 01:38:04,722 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 19\n","[2023-03-10 01:38:24,006 INFO] Step 100/10000; acc: 22.5; ppl: 172.7; xent: 5.2; lr: 0.00100; sents:    6400; bsz:  927/ 911/64; 2860/2809 tok/s;     32 sec;\n","[2023-03-10 01:38:30,175 INFO] Step 200/10000; acc: 36.2; ppl:  49.5; xent: 3.9; lr: 0.00100; sents:    6400; bsz:  873/ 871/64; 14151/14113 tok/s;     39 sec;\n","[2023-03-10 01:38:36,812 INFO] Step 300/10000; acc: 39.1; ppl:  35.8; xent: 3.6; lr: 0.00100; sents:    6400; bsz:  928/ 912/64; 13981/13749 tok/s;     45 sec;\n","[2023-03-10 01:38:43,084 INFO] Step 400/10000; acc: 42.0; ppl:  28.5; xent: 3.4; lr: 0.00100; sents:    6400; bsz:  930/ 919/64; 14828/14645 tok/s;     51 sec;\n","[2023-03-10 01:38:49,618 INFO] Step 500/10000; acc: 45.5; ppl:  22.5; xent: 3.1; lr: 0.00100; sents:    6400; bsz:  871/ 866/64; 13324/13256 tok/s;     58 sec;\n","[2023-03-10 01:38:53,088 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.468529224395752 s.\n","[2023-03-10 01:38:53,088 INFO] Train perplexity: 45.8192\n","[2023-03-10 01:38:53,089 INFO] Train accuracy: 36.9616\n","[2023-03-10 01:38:53,089 INFO] Sentences processed: 32000\n","[2023-03-10 01:38:53,089 INFO] Average bsz:  906/ 896/64\n","[2023-03-10 01:38:53,089 INFO] Validation perplexity: 21.6338\n","[2023-03-10 01:38:53,089 INFO] Validation accuracy: 45.464\n","[2023-03-10 01:38:53,089 INFO] Model is improving ppl: inf --> 21.6338.\n","[2023-03-10 01:38:53,089 INFO] Model is improving acc: -inf --> 45.464.\n","[2023-03-10 01:38:53,093 INFO] Saving checkpoint /content/drive/MyDrive/lab3_results/multi30k/run/model_step_500.pt\n","[2023-03-10 01:39:00,243 INFO] Step 600/10000; acc: 47.8; ppl:  18.6; xent: 2.9; lr: 0.00100; sents:    6400; bsz:  862/ 861/64; 8113/8101 tok/s;     69 sec;\n","[2023-03-10 01:39:07,403 INFO] Step 700/10000; acc: 48.5; ppl:  17.5; xent: 2.9; lr: 0.00100; sents:    6400; bsz:  924/ 908/64; 12904/12679 tok/s;     76 sec;\n","[2023-03-10 01:39:13,897 INFO] Step 800/10000; acc: 51.2; ppl:  14.5; xent: 2.7; lr: 0.00100; sents:    6400; bsz:  892/ 886/64; 13744/13639 tok/s;     82 sec;\n","[2023-03-10 01:39:20,314 INFO] Step 900/10000; acc: 52.7; ppl:  12.9; xent: 2.6; lr: 0.00100; sents:    6355; bsz:  895/ 887/64; 13941/13819 tok/s;     89 sec;\n","[2023-03-10 01:39:26,734 INFO] Step 1000/10000; acc: 53.6; ppl:  12.0; xent: 2.5; lr: 0.00100; sents:    6400; bsz:  911/ 898/64; 14197/13984 tok/s;     95 sec;\n","[2023-03-10 01:39:31,308 INFO] valid stats calculation and sentences rebuilding\n","                           took: 4.57409143447876 s.\n","[2023-03-10 01:39:31,309 INFO] Train perplexity: 26.1659\n","[2023-03-10 01:39:31,309 INFO] Train accuracy: 43.8403\n","[2023-03-10 01:39:31,309 INFO] Sentences processed: 63955\n","[2023-03-10 01:39:31,309 INFO] Average bsz:  901/ 892/64\n","[2023-03-10 01:39:31,309 INFO] Validation perplexity: 12.274\n","[2023-03-10 01:39:31,309 INFO] Validation accuracy: 54.0235\n","[2023-03-10 01:39:31,309 INFO] Model is improving ppl: 21.6338 --> 12.274.\n","[2023-03-10 01:39:31,309 INFO] Model is improving acc: 45.464 --> 54.0235.\n","[2023-03-10 01:39:31,313 INFO] Saving checkpoint /content/drive/MyDrive/lab3_results/multi30k/run/model_step_1000.pt\n","[2023-03-10 01:39:37,992 INFO] Step 1100/10000; acc: 56.1; ppl:  10.0; xent: 2.3; lr: 0.00100; sents:    6400; bsz:  868/ 866/64; 7712/7696 tok/s;    106 sec;\n","[2023-03-10 01:39:46,062 INFO] Step 1200/10000; acc: 57.0; ppl:   9.2; xent: 2.2; lr: 0.00100; sents:    6400; bsz:  907/ 900/64; 11238/11155 tok/s;    114 sec;\n","[2023-03-10 01:39:51,944 INFO] Step 1300/10000; acc: 60.3; ppl:   7.4; xent: 2.0; lr: 0.00100; sents:    6400; bsz:  862/ 864/64; 14648/14685 tok/s;    120 sec;\n","[2023-03-10 01:39:59,234 INFO] Step 1400/10000; acc: 57.9; ppl:   8.7; xent: 2.2; lr: 0.00100; sents:    6400; bsz:  972/ 954/64; 13333/13081 tok/s;    128 sec;\n","[2023-03-10 01:40:05,333 INFO] Step 1500/10000; acc: 61.1; ppl:   7.0; xent: 1.9; lr: 0.00100; sents:    6400; bsz:  906/ 896/64; 14856/14694 tok/s;    134 sec;\n","[2023-03-10 01:40:09,031 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.6971418857574463 s.\n","[2023-03-10 01:40:09,032 INFO] Train perplexity: 17.88\n","[2023-03-10 01:40:09,032 INFO] Train accuracy: 48.7384\n","[2023-03-10 01:40:09,032 INFO] Sentences processed: 95955\n","[2023-03-10 01:40:09,032 INFO] Average bsz:  902/ 893/64\n","[2023-03-10 01:40:09,032 INFO] Validation perplexity: 8.7167\n","[2023-03-10 01:40:09,032 INFO] Validation accuracy: 59.7022\n","[2023-03-10 01:40:09,032 INFO] Model is improving ppl: 12.274 --> 8.7167.\n","[2023-03-10 01:40:09,032 INFO] Model is improving acc: 54.0235 --> 59.7022.\n","[2023-03-10 01:40:09,037 INFO] Saving checkpoint /content/drive/MyDrive/lab3_results/multi30k/run/model_step_1500.pt\n","[2023-03-10 01:40:16,878 INFO] Step 1600/10000; acc: 61.7; ppl:   6.8; xent: 1.9; lr: 0.00100; sents:    6400; bsz:  924/ 916/64; 8008/7934 tok/s;    145 sec;\n","[2023-03-10 01:40:23,916 INFO] Step 1700/10000; acc: 64.5; ppl:   5.5; xent: 1.7; lr: 0.00100; sents:    6400; bsz:  920/ 907/64; 13073/12886 tok/s;    152 sec;\n","[2023-03-10 01:40:30,696 INFO] Step 1800/10000; acc: 64.8; ppl:   5.5; xent: 1.7; lr: 0.00100; sents:    6400; bsz:  928/ 911/64; 13689/13441 tok/s;    159 sec;\n","[2023-03-10 01:40:36,896 INFO] Step 1900/10000; acc: 66.1; ppl:   5.1; xent: 1.6; lr: 0.00100; sents:    6400; bsz:  921/ 910/64; 14849/14678 tok/s;    165 sec;\n","[2023-03-10 01:40:43,818 INFO] Step 2000/10000; acc: 67.8; ppl:   4.6; xent: 1.5; lr: 0.00100; sents:    6400; bsz:  916/ 906/64; 13237/13094 tok/s;    172 sec;\n","[2023-03-10 01:40:48,780 INFO] valid stats calculation and sentences rebuilding\n","                           took: 4.960585117340088 s.\n","[2023-03-10 01:40:48,781 INFO] Train perplexity: 13.2323\n","[2023-03-10 01:40:48,781 INFO] Train accuracy: 52.8546\n","[2023-03-10 01:40:48,781 INFO] Sentences processed: 127955\n","[2023-03-10 01:40:48,781 INFO] Average bsz:  907/ 897/64\n","[2023-03-10 01:40:48,781 INFO] Validation perplexity: 6.77507\n","[2023-03-10 01:40:48,781 INFO] Validation accuracy: 64.5499\n","[2023-03-10 01:40:48,781 INFO] Model is improving ppl: 8.7167 --> 6.77507.\n","[2023-03-10 01:40:48,781 INFO] Model is improving acc: 59.7022 --> 64.5499.\n","[2023-03-10 01:40:48,787 INFO] Saving checkpoint /content/drive/MyDrive/lab3_results/multi30k/run/model_step_2000.pt\n","[2023-03-10 01:40:56,725 INFO] Step 2100/10000; acc: 69.2; ppl:   4.2; xent: 1.4; lr: 0.00100; sents:    6400; bsz:  958/ 941/64; 7423/7291 tok/s;    185 sec;\n","[2023-03-10 01:41:03,508 INFO] Step 2200/10000; acc: 70.4; ppl:   3.9; xent: 1.4; lr: 0.00100; sents:    6400; bsz:  904/ 894/64; 13324/13185 tok/s;    192 sec;\n","[2023-03-10 01:41:10,149 INFO] Step 2300/10000; acc: 71.5; ppl:   3.8; xent: 1.3; lr: 0.00100; sents:    6400; bsz:  871/ 869/64; 13109/13084 tok/s;    199 sec;\n","[2023-03-10 01:41:16,016 INFO] Step 2400/10000; acc: 74.1; ppl:   3.2; xent: 1.2; lr: 0.00100; sents:    6400; bsz:  856/ 857/64; 14587/14616 tok/s;    204 sec;\n","[2023-03-10 01:41:22,922 INFO] Step 2500/10000; acc: 72.9; ppl:   3.4; xent: 1.2; lr: 0.00100; sents:    6400; bsz:  948/ 936/64; 13726/13558 tok/s;    211 sec;\n","[2023-03-10 01:41:26,943 INFO] valid stats calculation and sentences rebuilding\n","                           took: 4.020720481872559 s.\n","[2023-03-10 01:41:26,944 INFO] Train perplexity: 10.2481\n","[2023-03-10 01:41:26,944 INFO] Train accuracy: 56.6085\n","[2023-03-10 01:41:26,944 INFO] Sentences processed: 159955\n","[2023-03-10 01:41:26,944 INFO] Average bsz:  907/ 898/64\n","[2023-03-10 01:41:26,944 INFO] Validation perplexity: 5.50998\n","[2023-03-10 01:41:26,944 INFO] Validation accuracy: 68.1856\n","[2023-03-10 01:41:26,944 INFO] Model is improving ppl: 6.77507 --> 5.50998.\n","[2023-03-10 01:41:26,944 INFO] Model is improving acc: 64.5499 --> 68.1856.\n","[2023-03-10 01:41:26,948 INFO] Saving checkpoint /content/drive/MyDrive/lab3_results/multi30k/run/model_step_2500.pt\n","[2023-03-10 01:41:34,189 INFO] Step 2600/10000; acc: 74.0; ppl:   3.2; xent: 1.2; lr: 0.00100; sents:    6400; bsz:  955/ 944/64; 8472/8380 tok/s;    223 sec;\n","[2023-03-10 01:41:41,663 INFO] Step 2700/10000; acc: 75.8; ppl:   2.9; xent: 1.1; lr: 0.00100; sents:    6400; bsz:  861/ 857/64; 11516/11471 tok/s;    230 sec;\n","[2023-03-10 01:41:47,423 INFO] Step 2800/10000; acc: 77.2; ppl:   2.7; xent: 1.0; lr: 0.00100; sents:    6400; bsz:  847/ 849/64; 14702/14741 tok/s;    236 sec;\n","[2023-03-10 01:41:54,410 INFO] Step 2900/10000; acc: 76.4; ppl:   2.8; xent: 1.0; lr: 0.00100; sents:    6400; bsz:  923/ 915/64; 13219/13096 tok/s;    243 sec;\n","[2023-03-10 01:42:00,658 INFO] Step 3000/10000; acc: 77.1; ppl:   2.7; xent: 1.0; lr: 0.00100; sents:    6400; bsz:  926/ 909/64; 14827/14554 tok/s;    249 sec;\n","[2023-03-10 01:42:04,520 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.862063407897949 s.\n","[2023-03-10 01:42:04,521 INFO] Train perplexity: 8.29004\n","[2023-03-10 01:42:04,521 INFO] Train accuracy: 59.8403\n","[2023-03-10 01:42:04,521 INFO] Sentences processed: 191955\n","[2023-03-10 01:42:04,521 INFO] Average bsz:  906/ 897/64\n","[2023-03-10 01:42:04,521 INFO] Validation perplexity: 5.11573\n","[2023-03-10 01:42:04,521 INFO] Validation accuracy: 69.9931\n","[2023-03-10 01:42:04,522 INFO] Model is improving ppl: 5.50998 --> 5.11573.\n","[2023-03-10 01:42:04,522 INFO] Model is improving acc: 68.1856 --> 69.9931.\n","[2023-03-10 01:42:04,526 INFO] Saving checkpoint /content/drive/MyDrive/lab3_results/multi30k/run/model_step_3000.pt\n","[2023-03-10 01:42:12,247 INFO] Step 3100/10000; acc: 78.0; ppl:   2.6; xent: 0.9; lr: 0.00100; sents:    6400; bsz:  934/ 924/64; 8062/7971 tok/s;    261 sec;\n","[2023-03-10 01:42:19,284 INFO] Step 3200/10000; acc: 78.4; ppl:   2.5; xent: 0.9; lr: 0.00100; sents:    6400; bsz:  912/ 899/64; 12959/12777 tok/s;    268 sec;\n","[2023-03-10 01:42:25,933 INFO] Step 3300/10000; acc: 79.1; ppl:   2.4; xent: 0.9; lr: 0.00100; sents:    6400; bsz:  905/ 898/64; 13614/13511 tok/s;    274 sec;\n","[2023-03-10 01:42:31,984 INFO] Step 3400/10000; acc: 81.1; ppl:   2.2; xent: 0.8; lr: 0.00100; sents:    6400; bsz:  898/ 886/64; 14847/14647 tok/s;    280 sec;\n","[2023-03-10 01:42:38,848 INFO] Step 3500/10000; acc: 79.5; ppl:   2.4; xent: 0.9; lr: 0.00100; sents:    6400; bsz:  913/ 898/64; 13294/13086 tok/s;    287 sec;\n","[2023-03-10 01:42:42,315 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.4662187099456787 s.\n","[2023-03-10 01:42:42,316 INFO] Train perplexity: 6.94006\n","[2023-03-10 01:42:42,316 INFO] Train accuracy: 62.6194\n","[2023-03-10 01:42:42,316 INFO] Sentences processed: 223955\n","[2023-03-10 01:42:42,316 INFO] Average bsz:  907/ 898/64\n","[2023-03-10 01:42:42,316 INFO] Validation perplexity: 4.9189\n","[2023-03-10 01:42:42,316 INFO] Validation accuracy: 70.8172\n","[2023-03-10 01:42:42,316 INFO] Model is improving ppl: 5.11573 --> 4.9189.\n","[2023-03-10 01:42:42,316 INFO] Model is improving acc: 69.9931 --> 70.8172.\n","[2023-03-10 01:42:42,320 INFO] Saving checkpoint /content/drive/MyDrive/lab3_results/multi30k/run/model_step_3500.pt\n","[2023-03-10 01:42:49,744 INFO] Step 3600/10000; acc: 81.0; ppl:   2.2; xent: 0.8; lr: 0.00100; sents:    6400; bsz:  904/ 898/64; 8298/8244 tok/s;    298 sec;\n","[2023-03-10 01:42:56,806 INFO] Step 3700/10000; acc: 81.8; ppl:   2.1; xent: 0.7; lr: 0.00100; sents:    6400; bsz:  934/ 916/64; 13219/12969 tok/s;    305 sec;\n","[2023-03-10 01:43:03,400 INFO] Step 3800/10000; acc: 82.3; ppl:   2.0; xent: 0.7; lr: 0.00100; sents:    6400; bsz:  908/ 899/64; 13777/13639 tok/s;    312 sec;\n","[2023-03-10 01:43:09,916 INFO] Step 3900/10000; acc: 81.2; ppl:   2.2; xent: 0.8; lr: 0.00100; sents:    6400; bsz:  925/ 911/64; 14202/13983 tok/s;    318 sec;\n","[2023-03-10 01:43:16,206 INFO] Step 4000/10000; acc: 83.9; ppl:   1.9; xent: 0.6; lr: 0.00100; sents:    6400; bsz:  890/ 885/64; 14146/14078 tok/s;    325 sec;\n","[2023-03-10 01:43:20,819 INFO] valid stats calculation and sentences rebuilding\n","                           took: 4.612025737762451 s.\n","[2023-03-10 01:43:20,820 INFO] Train perplexity: 5.9607\n","[2023-03-10 01:43:20,820 INFO] Train accuracy: 65.0554\n","[2023-03-10 01:43:20,820 INFO] Sentences processed: 255955\n","[2023-03-10 01:43:20,820 INFO] Average bsz:  908/ 898/64\n","[2023-03-10 01:43:20,820 INFO] Validation perplexity: 5.12601\n","[2023-03-10 01:43:20,820 INFO] Validation accuracy: 71.0319\n","[2023-03-10 01:43:20,820 INFO] Stalled patience: 1/2\n","[2023-03-10 01:43:20,824 INFO] Saving checkpoint /content/drive/MyDrive/lab3_results/multi30k/run/model_step_4000.pt\n","[2023-03-10 01:43:27,876 INFO] Step 4100/10000; acc: 83.7; ppl:   1.9; xent: 0.6; lr: 0.00100; sents:    6400; bsz:  922/ 913/64; 7900/7822 tok/s;    336 sec;\n","[2023-03-10 01:43:35,585 INFO] Step 4200/10000; acc: 84.3; ppl:   1.9; xent: 0.6; lr: 0.00100; sents:    6400; bsz:  887/ 879/64; 11506/11399 tok/s;    344 sec;\n","[2023-03-10 01:43:42,144 INFO] Step 4300/10000; acc: 82.4; ppl:   2.1; xent: 0.7; lr: 0.00100; sents:    6400; bsz:  976/ 953/64; 14886/14526 tok/s;    351 sec;\n","[2023-03-10 01:43:48,853 INFO] Step 4400/10000; acc: 85.1; ppl:   1.8; xent: 0.6; lr: 0.00100; sents:    6400; bsz:  881/ 877/64; 13136/13078 tok/s;    357 sec;\n","[2023-03-10 01:43:54,862 INFO] Step 4500/10000; acc: 85.1; ppl:   1.8; xent: 0.6; lr: 0.00100; sents:    6400; bsz:  883/ 877/64; 14697/14603 tok/s;    363 sec;\n","[2023-03-10 01:43:58,525 INFO] valid stats calculation and sentences rebuilding\n","                           took: 3.6626217365264893 s.\n","[2023-03-10 01:43:58,526 INFO] Train perplexity: 5.24117\n","[2023-03-10 01:43:58,526 INFO] Train accuracy: 67.1737\n","[2023-03-10 01:43:58,526 INFO] Sentences processed: 287955\n","[2023-03-10 01:43:58,526 INFO] Average bsz:  908/ 899/64\n","[2023-03-10 01:43:58,526 INFO] Validation perplexity: 5.16741\n","[2023-03-10 01:43:58,526 INFO] Validation accuracy: 71.482\n","[2023-03-10 01:43:58,526 INFO] Stalled patience: 0/2\n","[2023-03-10 01:43:58,527 INFO] Training finished after stalled validations. Early Stop!\n","[2023-03-10 01:43:58,527 INFO] Best model found at step 3500\n","[2023-03-10 01:43:58,527 INFO] earlystopper has_stopped!\n","[2023-03-10 01:44:01,162 INFO] Saving checkpoint /content/drive/MyDrive/lab3_results/multi30k/run/model_step_4500.pt\n"]}],"source":["## Code to create predictions\n","!onmt_train -config /content/drive/MyDrive/COLX_531_lab3_jhlbxx/multi30k.yml"]},{"cell_type":"code","source":["!onmt_translate -model /content/drive/MyDrive/lab3_results/multi30k/run/model_step_3000.pt -src /content/drive/MyDrive/COLX_531_lab3_jhlbxx/data/val_fr.tokd -output /content/drive/MyDrive/lab3_results/multi30k/run/val_3000.txt -gpu 0 -beam_size 10 -seed 531 -block_ngram 2\n","!onmt_translate -model /content/drive/MyDrive/lab3_results/multi30k/run/model_step_3500.pt -src /content/drive/MyDrive/COLX_531_lab3_jhlbxx/data/val_fr.tokd -output /content/drive/MyDrive/lab3_results/multi30k/run/val_3500.txt -gpu 0 -beam_size 10 -seed 531 -block_ngram 2\n","!onmt_translate -model /content/drive/MyDrive/lab3_results/multi30k/run/model_step_4000.pt -src /content/drive/MyDrive/COLX_531_lab3_jhlbxx/data/val_fr.tokd -output /content/drive/MyDrive/lab3_results/multi30k/run/val_4000.txt -gpu 0 -beam_size 10 -seed 531 -block_ngram 2\n","!onmt_translate -model /content/drive/MyDrive/lab3_results/multi30k/run/model_step_4500.pt -src /content/drive/MyDrive/COLX_531_lab3_jhlbxx/data/val_fr.tokd -output /content/drive/MyDrive/lab3_results/multi30k/run/val_4500.txt -gpu 0 -beam_size 10 -seed 531 -block_ngram 2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jLGhL5wa-eRE","executionInfo":{"status":"ok","timestamp":1678412943328,"user_tz":480,"elapsed":129853,"user":{"displayName":"Hao Jia","userId":"07311169520047142158"}},"outputId":"8eacce42-dd97-401b-9744-8df933f78ccc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2023-03-10 01:47:27,365 INFO] PRED SCORE: -0.3187, PRED PPL: 1.38 NB SENTENCES: 1014\n","[2023-03-10 01:47:59,592 INFO] PRED SCORE: -0.2852, PRED PPL: 1.33 NB SENTENCES: 1014\n","[2023-03-10 01:48:31,087 INFO] PRED SCORE: -0.2513, PRED PPL: 1.29 NB SENTENCES: 1014\n","[2023-03-10 01:49:02,291 INFO] PRED SCORE: -0.2388, PRED PPL: 1.27 NB SENTENCES: 1014\n"]}]},{"cell_type":"code","source":["## Code to compute BLEU scores\n","!perl  OpenNMT-py/tools/multi-bleu-detok.perl /content/drive/MyDrive/COLX_531_lab3_jhlbxx/data/val_en.tokd < /content/drive/MyDrive/lab3_results/multi30k/run/val_3000.txt\n","!perl  OpenNMT-py/tools/multi-bleu-detok.perl /content/drive/MyDrive/COLX_531_lab3_jhlbxx/data/val_en.tokd < /content/drive/MyDrive/lab3_results/multi30k/run/val_3500.txt\n","!perl  OpenNMT-py/tools/multi-bleu-detok.perl /content/drive/MyDrive/COLX_531_lab3_jhlbxx/data/val_en.tokd < /content/drive/MyDrive/lab3_results/multi30k/run/val_4000.txt\n","!perl  OpenNMT-py/tools/multi-bleu-detok.perl /content/drive/MyDrive/COLX_531_lab3_jhlbxx/data/val_en.tokd < /content/drive/MyDrive/lab3_results/multi30k/run/val_4500.txt"],"metadata":{"id":"w6L8LlOfTp9j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678412959358,"user_tz":480,"elapsed":1907,"user":{"displayName":"Hao Jia","userId":"07311169520047142158"}},"outputId":"7f29d01b-f472-4f1d-ec9c-3e555ec27ac1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["BLEU = 36.11, 63.9/42.7/29.8/20.9 (BP=1.000, ratio=1.075, hyp_len=14439, ref_len=13431)\n","BLEU = 38.60, 66.9/45.5/32.1/22.7 (BP=1.000, ratio=1.034, hyp_len=13892, ref_len=13431)\n","BLEU = 39.77, 67.3/46.4/33.3/24.0 (BP=1.000, ratio=1.041, hyp_len=13984, ref_len=13431)\n","BLEU = 39.84, 67.3/46.6/33.4/24.1 (BP=1.000, ratio=1.044, hyp_len=14018, ref_len=13431)\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}